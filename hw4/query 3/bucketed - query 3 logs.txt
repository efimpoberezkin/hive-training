============================
Logs for Query 'use default'
============================


=========================================================================================================================================================================================================================================================================================================================================================================================================
Logs for Query 'SELECT airport, number_of_flights
FROM
(
  SELECT iata, COUNT(*) AS number_of_flights
  FROM
  (
    SELECT origin AS iata FROM flights_bucketed WHERE month IN (6,7,8)
    UNION ALL
    SELECT dest AS iata FROM flights_bucketed WHERE month IN (6,7,8)
  ) t1
  GROUP BY iata
) f
JOIN airports a ON f.iata = a.iata
WHERE a.country = 'USA'
ORDER BY number_of_flights DESC LIMIT 5'
=========================================================================================================================================================================================================================================================================================================================================================================================================

INFO  : Number of reduce tasks not specified. Estimated from input data size: 11
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : number of splits:3
INFO  : Submitting tokens for job: job_1517995013177_0081
INFO  : The url to track the job: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1517995013177_0081/
INFO  : Starting Job = job_1517995013177_0081, Tracking URL = http://sandbox-hdp.hortonworks.com:8088/proxy/application_1517995013177_0081/
INFO  : Kill Command = /usr/hdp/2.6.3.0-235/hadoop/bin/hadoop job  -kill job_1517995013177_0081
INFO  : Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 11
INFO  : 2018-02-08 09:15:23,908 Stage-1 map = 0%,  reduce = 0%
INFO  : 2018-02-08 09:15:33,581 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 4.26 sec
INFO  : 2018-02-08 09:15:35,639 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 17.34 sec
INFO  : 2018-02-08 09:15:36,686 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 17.91 sec
INFO  : 2018-02-08 09:15:42,036 Stage-1 map = 100%,  reduce = 9%, Cumulative CPU 20.1 sec
INFO  : 2018-02-08 09:15:46,698 Stage-1 map = 100%,  reduce = 18%, Cumulative CPU 21.86 sec
INFO  : 2018-02-08 09:15:47,858 Stage-1 map = 100%,  reduce = 27%, Cumulative CPU 24.24 sec
INFO  : 2018-02-08 09:15:50,021 Stage-1 map = 100%,  reduce = 36%, Cumulative CPU 26.38 sec
INFO  : 2018-02-08 09:15:53,451 Stage-1 map = 100%,  reduce = 55%, Cumulative CPU 30.5 sec
INFO  : 2018-02-08 09:15:54,529 Stage-1 map = 100%,  reduce = 64%, Cumulative CPU 32.85 sec
INFO  : 2018-02-08 09:15:55,557 Stage-1 map = 100%,  reduce = 82%, Cumulative CPU 37.67 sec
INFO  : 2018-02-08 09:15:56,608 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 41.25 sec
INFO  : MapReduce Total cumulative CPU time: 41 seconds 250 msec
INFO  : Ended Job = job_1517995013177_0081
INFO  : Execution completed successfully
INFO  : MapredLocal task succeeded
INFO  : Number of reduce tasks determined at compile time: 1
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : number of splits:1
INFO  : Submitting tokens for job: job_1517995013177_0082
INFO  : The url to track the job: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1517995013177_0082/
INFO  : Starting Job = job_1517995013177_0082, Tracking URL = http://sandbox-hdp.hortonworks.com:8088/proxy/application_1517995013177_0082/
INFO  : Kill Command = /usr/hdp/2.6.3.0-235/hadoop/bin/hadoop job  -kill job_1517995013177_0082
INFO  : Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
INFO  : 2018-02-08 09:16:06,191 Stage-3 map = 0%,  reduce = 0%
INFO  : 2018-02-08 09:16:11,416 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.64 sec
INFO  : 2018-02-08 09:16:17,611 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.2 sec
INFO  : MapReduce Total cumulative CPU time: 4 seconds 200 msec
INFO  : Ended Job = job_1517995013177_0082